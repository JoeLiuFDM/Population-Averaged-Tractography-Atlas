{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-13T01:49:53.399317Z",
     "start_time": "2026-02-13T01:49:51.904251Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "\n",
    "from dipy.io.streamline import load_tractogram, save_tractogram\n",
    "from dipy.tracking.streamline import set_number_of_points\n",
    "from dipy.segment.clustering import QuickBundles\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import os\n",
    "from dipy.io.stateful_tractogram import StatefulTractogram, Space\n",
    "from dipy.tracking.streamline import transform_streamlines\n",
    "\n",
    "from dipy.align.imaffine import (\n",
    "    AffineRegistration,\n",
    "    MutualInformationMetric,\n",
    "    transform_centers_of_mass,\n",
    ")\n",
    "from dipy.align.transforms import TranslationTransform3D, RigidTransform3D, AffineTransform3D"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trk_dir = Path(\"Problematic Track List/IPL\")  # folder containing *.trk files\n",
    "reference_nii = Path(\"MNI152_T1_2mm.nii.gz\")  # used for loading/saving coordinates\n",
    "\n",
    "out_dir = Path(\"derivatives/atlas_trk_IPL\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "n_points = 100          # resample points per streamline for clustering stability\n",
    "balanced_n = 200        # per-subject streamline count for fair pooling\n",
    "qb_threshold = 10.0     # clustering threshold (mm-ish if your space is mm)\n",
    "qb_max_clusters = 50    # cap to avoid explosion\n",
    "\n",
    "rng_seed = 0\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-13T03:13:51.387013Z",
     "start_time": "2026-02-13T03:13:51.381874Z"
    }
   },
   "id": "ea6c6c44d91dc9ba",
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def _to_rasmm_inplace_compatible(sft):\n",
    "    \"\"\"DIPY-version-safe conversion to RASMM.\"\"\"\n",
    "    ret = sft.to_space(Space.RASMM)  # some versions return None (in-place)\n",
    "    return sft if ret is None else ret\n",
    "\n",
    "\n",
    "def compute_native_to_mni_affine_dipy(\n",
    "    native_b0_nii: str,\n",
    "    mni_ref_nii: str,\n",
    "    nbins: int = 32,\n",
    "    level_iters=(1000, 200, 50),\n",
    "    sigmas=(3.0, 1.0, 0.0),\n",
    "    factors=(4, 2, 1),\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Compute affine mapping native(b0) RASMM -> MNI RASMM using DIPY imaffine.\"\"\"\n",
    "    if not os.path.exists(native_b0_nii):\n",
    "        raise FileNotFoundError(f\"Native b0 NIfTI not found: {native_b0_nii}\")\n",
    "    if not os.path.exists(mni_ref_nii):\n",
    "        raise FileNotFoundError(f\"MNI reference NIfTI not found: {mni_ref_nii}\")\n",
    "\n",
    "    native_img = nib.load(native_b0_nii)\n",
    "    mni_img = nib.load(mni_ref_nii)\n",
    "\n",
    "    static = mni_img.get_fdata().astype(np.float32)     # target (MNI)\n",
    "    moving = native_img.get_fdata().astype(np.float32)  # source (native)\n",
    "\n",
    "    static_aff = mni_img.affine\n",
    "    moving_aff = native_img.affine\n",
    "\n",
    "    metric = MutualInformationMetric(nbins=nbins, sampling_proportion=None)\n",
    "    affreg = AffineRegistration(metric=metric, level_iters=level_iters, sigmas=sigmas, factors=factors)\n",
    "\n",
    "    com = transform_centers_of_mass(static, static_aff, moving, moving_aff)\n",
    "\n",
    "    trans = affreg.optimize(\n",
    "        static, moving,\n",
    "        transform=TranslationTransform3D(),\n",
    "        params0=None,\n",
    "        static_grid2world=static_aff,\n",
    "        moving_grid2world=moving_aff,\n",
    "        starting_affine=com.affine\n",
    "    )\n",
    "\n",
    "    rigid = affreg.optimize(\n",
    "        static, moving,\n",
    "        transform=RigidTransform3D(),\n",
    "        params0=None,\n",
    "        static_grid2world=static_aff,\n",
    "        moving_grid2world=moving_aff,\n",
    "        starting_affine=trans.affine\n",
    "    )\n",
    "\n",
    "    aff = affreg.optimize(\n",
    "        static, moving,\n",
    "        transform=AffineTransform3D(),\n",
    "        params0=None,\n",
    "        static_grid2world=static_aff,\n",
    "        moving_grid2world=moving_aff,\n",
    "        starting_affine=rigid.affine\n",
    "    )\n",
    "\n",
    "    return rigid.affine\n",
    "\n",
    "\n",
    "def default_subject_id_from_trk(trk_path: Path) -> str:\n",
    "    \"\"\"\n",
    "    Extract subject id from filename like IFG_Orb_001.trk -> '001'.\n",
    "    Adjust this if your naming differs.\n",
    "    \"\"\"\n",
    "    m = re.search(r\"(\\d+)(?=\\.trk$)\", trk_path.name)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Cannot parse subject id from: {trk_path.name}\")\n",
    "    return m.group(1)\n",
    "\n",
    "\n",
    "def find_subject_b0(subject_id: str, refs_root: Path) -> Path:\n",
    "    patterns = [\n",
    "        f\"**/data{subject_id}_HARDI_DWIb0.nii\",\n",
    "        f\"**/data{subject_id}_HARDI_DWIb0.nii.gz\",\n",
    "        f\"**/data{int(subject_id)}_HARDI_DWIb0.nii\",      # in case id not zero-padded on disk\n",
    "        f\"**/data{int(subject_id)}_HARDI_DWIb0.nii.gz\",\n",
    "    ]\n",
    "    hits = []\n",
    "    for pat in patterns:\n",
    "        hits.extend(list(refs_root.glob(pat)))\n",
    "\n",
    "    # de-duplicate\n",
    "    hits = sorted(set(hits))\n",
    "    if len(hits) == 0:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No b0 found for subject_id={subject_id} under {refs_root}.\\n\"\n",
    "            f\"Tried patterns: {patterns}\"\n",
    "        )\n",
    "    if len(hits) > 1:\n",
    "        raise RuntimeError(\n",
    "            f\"Multiple b0 candidates for subject_id={subject_id}:\\n\" +\n",
    "            \"\\n\".join(str(h) for h in hits)\n",
    "        )\n",
    "    return hits[0]\n",
    "\n",
    "\n",
    "def register_trks_to_mni_per_subject(\n",
    "    trk_paths,\n",
    "    refs_root: str,\n",
    "    mni_reference_nii: str,\n",
    "    out_dir: str,\n",
    "    suffix: str = \"_MNI\",\n",
    "    overwrite: bool = False,\n",
    "    id_parser=default_subject_id_from_trk,):\n",
    "    \"\"\"\n",
    "    Register many .trk files into MNI space, using a matching per-subject b0 reference\n",
    "    located somewhere under refs_root.\n",
    "\n",
    "    - Caches per-subject affines.\n",
    "    - Saves each output TRK with MNI reference.\n",
    "    \"\"\"\n",
    "    refs_root = Path(refs_root)\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if not os.path.exists(mni_reference_nii):\n",
    "        raise FileNotFoundError(f\"MNI reference NIfTI not found: {mni_reference_nii}\")\n",
    "\n",
    "    mni_img = nib.load(mni_reference_nii)\n",
    "    affine_cache = {}  # subject_id -> (A_native_to_mni, native_b0_path)\n",
    "\n",
    "    for p in trk_paths:\n",
    "        p = Path(p)\n",
    "        subj_id = id_parser(p)\n",
    "\n",
    "        out_path = out_dir / f\"{p.stem}{suffix}{p.suffix}\"\n",
    "        if out_path.exists() and not overwrite:\n",
    "            continue\n",
    "\n",
    "        # Find the subject's native reference b0\n",
    "        native_b0 = find_subject_b0(subj_id, refs_root)\n",
    "\n",
    "        # Compute / reuse subject affine\n",
    "        if subj_id not in affine_cache:\n",
    "            A = compute_native_to_mni_affine_dipy(\n",
    "                native_b0_nii=str(native_b0),\n",
    "                mni_ref_nii=str(mni_reference_nii),\n",
    "            )\n",
    "            affine_cache[subj_id] = (A, native_b0)\n",
    "        else:\n",
    "            A, _ = affine_cache[subj_id]\n",
    "\n",
    "        # Load tractogram using subject-specific native reference\n",
    "        sft = load_tractogram(str(p), reference=str(native_b0), bbox_valid_check=False)\n",
    "        if sft is None:\n",
    "            raise RuntimeError(f\"Failed to load {p} with reference {native_b0}\")\n",
    "        ret = sft.to_space(Space.RASMM)\n",
    "        if ret is not None:\n",
    "            sft = ret\n",
    "        # sft = _to_rasmm_inplace_compatible(sft)\n",
    "        streams_mni = list(transform_streamlines(sft.streamlines, A))\n",
    "\n",
    "        out_sft = StatefulTractogram(streams_mni, mni_img, Space.RASMM)\n",
    "        save_tractogram(out_sft, str(out_path), bbox_valid_check=False)\n",
    "\n",
    "    return affine_cache  # so you can inspect per-subject transforms\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-13T03:13:52.162752Z",
     "start_time": "2026-02-13T03:13:52.151520Z"
    }
   },
   "id": "3b819579ad62d804",
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects registered: []\n"
     ]
    }
   ],
   "source": [
    "trk_paths = sorted(trk_dir.glob(\"*.trk\"))\n",
    "\n",
    "affines = register_trks_to_mni_per_subject(\n",
    "    trk_paths=trk_paths,\n",
    "    refs_root=\"derivatives/references\",        # root folder containing data001/, data002/, ...\n",
    "    mni_reference_nii=\"MNI152_T1_2mm.nii.gz\",\n",
    "    out_dir=\"derivatives/registration/IPL\",\n",
    "    overwrite=False\n",
    ")\n",
    "\n",
    "print(\"Subjects registered:\", sorted(affines.keys()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-13T03:13:53.683702Z",
     "start_time": "2026-02-13T03:13:53.676668Z"
    }
   },
   "id": "c63e4bcc618ed78e",
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "       subject  n_streamlines\n6  IPL_008_MNI            353\n5  IPL_006_MNI            278\n4  IPL_005_MNI            249\n3  IPL_004_MNI            229\n2  IPL_003_MNI            215\n7  IPL_009_MNI            189\n1  IPL_002_MNI             93\n0  IPL_001_MNI             68\n8  IPL_010_MNI             56",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject</th>\n      <th>n_streamlines</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>IPL_008_MNI</td>\n      <td>353</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>IPL_006_MNI</td>\n      <td>278</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>IPL_005_MNI</td>\n      <td>249</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>IPL_004_MNI</td>\n      <td>229</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>IPL_003_MNI</td>\n      <td>215</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>IPL_009_MNI</td>\n      <td>189</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>IPL_002_MNI</td>\n      <td>93</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>IPL_001_MNI</td>\n      <td>68</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>IPL_010_MNI</td>\n      <td>56</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_subject_streamlines(trk_path, reference_nii, n_points):\n",
    "    tg = load_tractogram(str(trk_path), reference=str(reference_nii), bbox_valid_check=False)\n",
    "    if tg is None:\n",
    "        return []\n",
    "    ret = tg.to_space(Space.RASMM)\n",
    "    if ret is not None:\n",
    "        tg = ret\n",
    "    streams = list(tg.streamlines)\n",
    "    if len(streams) == 0:\n",
    "        return []\n",
    "    streams = set_number_of_points(streams, n_points)\n",
    "    return streams\n",
    "\n",
    "trk_dir_mni = Path(\"derivatives/registration/IPL\")\n",
    "trk_paths = sorted(trk_dir_mni.glob(\"*_MNI.trk\"))\n",
    "# trk_paths = sorted(trk_dir.glob(\"*.trk\"))\n",
    "assert len(trk_paths) > 0, f\"No .trk found in {trk_dir}\"\n",
    "\n",
    "streams_by_subj = []\n",
    "subj_ids = []\n",
    "\n",
    "for p in trk_paths:\n",
    "    s = load_subject_streamlines(p, reference_nii, n_points)\n",
    "    streams_by_subj.append(s)\n",
    "    subj_ids.append(p.stem)\n",
    "\n",
    "counts = [len(s) for s in streams_by_subj]\n",
    "pd.DataFrame({\"subject\": subj_ids, \"n_streamlines\": counts}).sort_values(\"n_streamlines\", ascending=False).head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-13T03:13:54.717613Z",
     "start_time": "2026-02-13T03:13:54.642365Z"
    }
   },
   "id": "d1cc60ca851e86d2",
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(1406, [('IPL_001_MNI', 68), ('IPL_002_MNI', 93), ('IPL_003_MNI', 200)])"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def subject_balanced_pool(streams_by_subj, subj_ids, n_per_subj, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    pooled = []\n",
    "    kept = {}\n",
    "    for sid, s in zip(subj_ids, streams_by_subj):\n",
    "        s = list(s)\n",
    "        if len(s) == 0:\n",
    "            kept[sid] = 0\n",
    "            continue\n",
    "        if len(s) <= n_per_subj:\n",
    "            pooled.extend(s)\n",
    "            kept[sid] = len(s)\n",
    "        else:\n",
    "            idx = rng.choice(len(s), size=n_per_subj, replace=False)\n",
    "            pooled.extend([s[i] for i in idx])\n",
    "            kept[sid] = n_per_subj\n",
    "    return pooled, kept\n",
    "\n",
    "balanced_pool, kept_counts = subject_balanced_pool(streams_by_subj, subj_ids, balanced_n, seed=rng_seed)\n",
    "len(balanced_pool), list(kept_counts.items())[:3]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-13T03:13:55.561221Z",
     "start_time": "2026-02-13T03:13:55.555155Z"
    }
   },
   "id": "7b8ff9283bb6eb9e",
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def save_trk_streamlines(streamlines, reference_nii, out_path):\n",
    "    ref_img = nib.load(str(reference_nii))\n",
    "    sft = StatefulTractogram(streamlines, ref_img, Space.RASMM)\n",
    "    save_tractogram(sft, str(out_path), bbox_valid_check=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-13T03:13:55.995829Z",
     "start_time": "2026-02-13T03:13:55.991783Z"
    }
   },
   "id": "9d40a2b00cb4c8e3",
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "    cluster_id  cluster_size    weight\n15          15           284  0.201991\n20          20           155  0.110242\n27          27           148  0.105263\n5            5           144  0.102418\n12          12           134  0.095306\n7            7           126  0.089616\n13          13            65  0.046230\n30          30            50  0.035562\n2            2            39  0.027738\n1            1            30  0.021337",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cluster_id</th>\n      <th>cluster_size</th>\n      <th>weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>284</td>\n      <td>0.201991</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>20</td>\n      <td>155</td>\n      <td>0.110242</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>27</td>\n      <td>148</td>\n      <td>0.105263</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>144</td>\n      <td>0.102418</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>134</td>\n      <td>0.095306</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>126</td>\n      <td>0.089616</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>65</td>\n      <td>0.046230</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>30</td>\n      <td>50</td>\n      <td>0.035562</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>39</td>\n      <td>0.027738</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>30</td>\n      <td>0.021337</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qb = QuickBundles(threshold=qb_threshold, max_nb_clusters=qb_max_clusters)\n",
    "clusters = qb.cluster(balanced_pool)\n",
    "\n",
    "centroids = [c.centroid for c in clusters]\n",
    "cluster_sizes = np.array([len(c) for c in clusters], dtype=int)\n",
    "weights = cluster_sizes / cluster_sizes.sum()\n",
    "\n",
    "# Save centroids .trk\n",
    "centroid_trk = out_dir / f\"atlasA_centroids_thr{qb_threshold}_K{len(centroids)}.trk\"\n",
    "save_trk_streamlines(centroids, reference_nii, centroid_trk)\n",
    "\n",
    "# Save weights table\n",
    "dfA = pd.DataFrame({\n",
    "    \"cluster_id\": np.arange(len(centroids)),\n",
    "    \"cluster_size\": cluster_sizes,\n",
    "    \"weight\": weights\n",
    "}).sort_values(\"weight\", ascending=False)\n",
    "\n",
    "dfA.to_csv(out_dir / f\"atlasA_centroids_thr{qb_threshold}_weights.csv\", index=False)\n",
    "\n",
    "dfA.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-13T03:13:56.418449Z",
     "start_time": "2026-02-13T03:13:56.393842Z"
    }
   },
   "id": "7042bd64934d2e82",
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "WindowsPath('derivatives/atlas_trk_IPL/atlasB_population_balanced_n200_total1406.trk')"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_trk = out_dir / f\"atlasB_population_balanced_n{balanced_n}_total{len(balanced_pool)}.trk\"\n",
    "save_trk_streamlines(balanced_pool, reference_nii, pop_trk)\n",
    "\n",
    "pop_trk"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-13T03:13:56.951944Z",
     "start_time": "2026-02-13T03:13:56.917961Z"
    }
   },
   "id": "54d2c5b0122d5eb7",
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "WindowsPath('derivatives/atlas_trk_IPL/atlasB_population_balanced_light10k.trk')"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def downsample_streamlines(streamlines, n_total=10000, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    if len(streamlines) <= n_total:\n",
    "        return list(streamlines)\n",
    "    idx = rng.choice(len(streamlines), size=n_total, replace=False)\n",
    "    return [streamlines[i] for i in idx]\n",
    "\n",
    "pop_light = downsample_streamlines(balanced_pool, n_total=10000, seed=rng_seed)\n",
    "pop_light_trk = out_dir / f\"atlasB_population_balanced_light10k.trk\"\n",
    "save_trk_streamlines(pop_light, reference_nii, pop_light_trk)\n",
    "pop_light_trk"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-13T03:13:57.478836Z",
     "start_time": "2026-02-13T03:13:57.443147Z"
    }
   },
   "id": "85a76e361e144fe5",
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-13T02:52:18.727398Z",
     "start_time": "2026-02-13T02:52:18.725036Z"
    }
   },
   "id": "4430dfe916d97e77",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "399383a52bcda05d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
